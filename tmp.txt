python3 seq2seq_attention.py --mode test --model_dir ../../../pytorch_data/09_13_2218 --encoder=encoder_2.pth --decoder=decoder_2.pth


decoder_output.data

output = F.log_softmax(self.out(output[0]), dim=1)
なのでsoftmaxで0~1にしたあと、logで -∞~0

<class 'torch.Tensor'>
torch.Size([1, 30005])
tensor([-11.0001,  -2.5442,  -2.7432,  ..., -10.7662, -10.3689,
        -11.1510])
