python3 seq2seq_attention.py --mode test --model_dir ../../../pytorch_data/09_13_2218 --encoder=encoder_2.pth --decoder=decoder_2.pth


decoder_output.data

output = F.log_softmax(self.out(output[0]), dim=1)
なのでsoftmaxで0~1にしたあと、logで -∞~0

<class 'torch.Tensor'>
torch.Size([1, 30005])
tensor([-11.0001,  -2.5442,  -2.7432,  ..., -10.7662, -10.3689,
        -11.1510])




	東大ロボが使用していた手法はKenLM（単なる統計情報？）
	https://github.com/kpu/kenlm
	https://arxiv.org/pdf/1601.01272.pdf
	
	つまりは言語モデルでできるとのことなので他の言語モデルもいくつか調べた
	
	RNNLM ToolKit（word2vecの人が作ったものらしい）
	http://www.fit.vutbr.cz/~imikolov/rnnlm/
	https://qiita.com/s_chag11/items/30cc939d159ad185f8e1
	
	attentionつきのRNNLM（↑とは別の人）
	https://github.com/ketranm/RMN
	
	そしてこの論文に他のテストデータセット載ってた
	https://stackoverflow.com/questions/44373470/get-the-microsoft-research-sentence-completion-challenge
	https://dl.acm.org/citation.cfm?id=2390940.2390944
	
	
	今後はこのテストデータも使う？
	ベースラインとして自分の学習データとテストデータでKenLM，RNNLM，attentionつきRNNLMをやってみる？
