python3 seq2seq_batch.py --mode test --model_dir ../../../pytorch_data/10_09_1136mini --encoder=encoder_100.pth --decoder=decoder_100.pth





	そしてこの論文に他のテストデータセット載ってた
	https://stackoverflow.com/questions/44373470/get-the-microsoft-research-sentence-completion-challenge
	https://dl.acm.org/citation.cfm?id=2390940.2390944


	今後はこのテストデータも使う？
	ベースラインとして自分の学習データとテストデータでKenLM，RNNLM，attentionつきRNNLMをやってみる？


  https://yidatao.github.io/2017-05-31/kenlm-ngram/
  この方法でkenLM、選択肢Bの方法ならできそうでは？




RNNLM系動かすの大変そうだからpytorchのexampleのやつ改変する？
https://github.com/pytorch/examples/tree/master/word_language_model
